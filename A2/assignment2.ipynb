{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3d8419-6975-43d0-85ab-3208960757d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfeb1fe-59fa-43d6-b5c9-af397e85012b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Image Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e974c06d-adb7-4787-a11e-5973037f058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, path, i):\n",
    "    # Resize and save image\n",
    "    image = Image.open(img)\n",
    "    image = image.resize((150,150))\n",
    "    image.save(path+'/'+str(i)+'.jpg')\n",
    "    return\n",
    "        \n",
    "def create_directory(path):\n",
    "    # Create directory for resized images\n",
    "    if os.path.isdir(path) == True:\n",
    "        print (\"directory exists: \" + path)\n",
    "        print ('deleting directory: ' + path)\n",
    "        shutil.rmtree(path)\n",
    "        os.mkdir(path)\n",
    "        print (\"directory created: \" + path)\n",
    "    else :\n",
    "        os.mkdir(path)\n",
    "        print (\"directory created: \" + path)\n",
    "    return\n",
    "\n",
    "def resize_images():\n",
    "    directories = glob.glob('flower_photos/*/')\n",
    "    path = os.path.join('resized')\n",
    "    # shutil.rmtree(path)\n",
    "    create_directory(path)\n",
    "\n",
    "    for directory in directories:\n",
    "        flower_type = str.split(directory,'/')[1]    \n",
    "       # path = os.path.join(path1,'resized',flower_type)\n",
    "        path2 = os.path.join('resized',flower_type)\n",
    "        create_directory(path2)\n",
    "        i = 0\n",
    "        images= glob.glob(directory+'/*.jpg')\n",
    "        for image in images:\n",
    "            resize_image(image, path2 , i)\n",
    "            i += 1\n",
    "    shutil.rmtree('flower_photos')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46901e7b-281d-49d1-ab97-67ea682ee6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  218M  100  218M    0     0  21.8M      0  0:00:09  0:00:09 --:--:-- 22.7M\n",
      "CPU times: user 636 ms, sys: 217 ms, total: 853 ms\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!curl -O http://download.tensorflow.org/example_images/flower_photos.tgz\n",
    "!tar -xf flower_photos.tgz\n",
    "os.remove(\"flower_photos.tgz\") \n",
    "#resize_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea0fef6-6042-4296-a3eb-5809a09ce472",
   "metadata": {},
   "source": [
    "# Split Images Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f550d92-9930-4643-875f-2a68083b5b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = glob.glob('resized/*/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36ce26b-ca72-4dcf-9b6c-b237848449ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ratio = 0.75\n",
    "trainDict = {'dandelion':[],'daisy':[],'tulips':[],'sunflowers':[],'roses':[]}\n",
    "\n",
    "for directory in directories:\n",
    "    images= glob.glob(directory+'/*.jpg')\n",
    "    print(directory,\": \", len(images))\n",
    "    tr_idx = round (tr_ratio * len(images))\n",
    "    train = images[:tr_idx]\n",
    "    \n",
    "    flower_type = str.split(directory,'/')[1] \n",
    "\n",
    "    for item in train:\n",
    "        trainDict[flower_type].append(train)\n",
    "\n",
    "#     test = images[tr_idx:]\n",
    "#     print(len(test)+len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1baa50cf-196d-410d-b45b-8a7839779f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-17 00:29:32.351901: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-17 00:29:32.351962: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf49ac3a-2d56-4194-be65-15e0d745b8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2753 files for training.\n",
      "Found 3670 files belonging to 5 classes.\n",
      "Using 917 files for validation.\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'flower_photos'\n",
    "# data_dir = pathlib.Path(data_dir)\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels='inferred',\n",
    "    validation_split=0.25,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(150, 150),\n",
    "    batch_size=32)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels='inferred',\n",
    "    validation_split=0.25,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(150, 150),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f955fada-caf8-4ec9-8cca-bfb40673e817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc7aa8d3-3e6b-4e8a-b3a8-f3e96aa48d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-17 00:51:19.147050: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2021-10-17 00:51:20.023971: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2021-10-17 00:51:20.319032: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 411041792 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 19s 0us/step\n",
      "553476096/553467096 [==============================] - 19s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-17 00:51:41.021610: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 411041792 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.VGG16(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48494c7d-3a2c-40cf-9861-5d260b1d8566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a4fdbe-54d1-476c-8c3b-7765d2110287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
