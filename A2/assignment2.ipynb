{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3d8419-6975-43d0-85ab-3208960757d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfeb1fe-59fa-43d6-b5c9-af397e85012b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Image Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e974c06d-adb7-4787-a11e-5973037f058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, path, i):\n",
    "    # Resize and save image\n",
    "    image = Image.open(img)\n",
    "    image = image.resize((150,150))\n",
    "    image.save(path+'/'+str(i)+'.jpg')\n",
    "    return\n",
    "        \n",
    "def create_directory(path):\n",
    "    # Create directory for resized images\n",
    "    if os.path.isdir(path) == True:\n",
    "        print (\"directory exists: \" + path)\n",
    "        print ('deleting directory: ' + path)\n",
    "        shutil.rmtree(path)\n",
    "        os.mkdir(path)\n",
    "        print (\"directory created: \" + path)\n",
    "    else :\n",
    "        os.mkdir(path)\n",
    "        print (\"directory created: \" + path)\n",
    "    return\n",
    "\n",
    "def resize_images():\n",
    "    directories = glob.glob('flower_photos/*/')\n",
    "    path = os.path.join('resized')\n",
    "    # shutil.rmtree(path)\n",
    "    create_directory(path)\n",
    "\n",
    "    for directory in directories:\n",
    "        flower_type = str.split(directory,'/')[1]    \n",
    "       # path = os.path.join(path1,'resized',flower_type)\n",
    "        path2 = os.path.join('resized',flower_type)\n",
    "        create_directory(path2)\n",
    "        i = 0\n",
    "        images= glob.glob(directory+'/*.jpg')\n",
    "        for image in images:\n",
    "            resize_image(image, path2 , i)\n",
    "            i += 1\n",
    "    shutil.rmtree('flower_photos')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a71d75b-c871-4ef9-9abb-b0de0fc4269e",
   "metadata": {},
   "source": [
    "%%time\n",
    "!curl -O http://download.tensorflow.org/example_images/flower_photos.tgz\n",
    "!tar -xf flower_photos.tgz\n",
    "os.remove(\"flower_photos.tgz\") \n",
    "resize_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea0fef6-6042-4296-a3eb-5809a09ce472",
   "metadata": {},
   "source": [
    "# Split Images Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f550d92-9930-4643-875f-2a68083b5b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = glob.glob('resized/*/')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "08e1be33-b707-444d-b1a5-198b0b433fc8",
   "metadata": {},
   "source": [
    "tr_ratio = 0.75\n",
    "trainDict = {'dandelion':[],'daisy':[],'tulips':[],'sunflowers':[],'roses':[]}\n",
    "\n",
    "for directory in directories:\n",
    "    images= glob.glob(directory+'/*.jpg')\n",
    "    print(directory,\": \", len(images))\n",
    "    tr_idx = round (tr_ratio * len(images))\n",
    "    train = images[:tr_idx]\n",
    "    \n",
    "    flower_type = str.split(directory,'/')[1] \n",
    "\n",
    "    for item in train:\n",
    "        trainDict[flower_type].append(train)\n",
    "\n",
    "#     test = images[tr_idx:]\n",
    "#     print(len(test)+len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1baa50cf-196d-410d-b45b-8a7839779f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-19 22:13:15.394542: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-19 22:13:15.394603: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf49ac3a-2d56-4194-be65-15e0d745b8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2753 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-19 22:13:19.063963: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-10-19 22:13:19.064028: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-10-19 22:13:19.064080: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sarthak-MacBookPro): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 917 files for validation.\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'resized'\n",
    "# data_dir = pathlib.Path(data_dir)\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels='inferred',\n",
    "    validation_split=0.25,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(150, 150),\n",
    "    batch_size=32)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels='inferred',\n",
    "    validation_split=0.25,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(150, 150),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f955fada-caf8-4ec9-8cca-bfb40673e817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18c1de8-61b6-4cb8-9b35-eabf935ee070",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35bd939d-2dce-40c8-adc6-6753c3fc892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_w, image_h = 150, 150\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc7aa8d3-3e6b-4e8a-b3a8-f3e96aa48d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.applications.VGG16(\n",
    "#     include_top=False,\n",
    "#     weights=\"imagenet\",\n",
    "#     input_tensor=None,\n",
    "#     input_shape=None,\n",
    "#     pooling=None,\n",
    "#     classes=5,\n",
    "#     classifier_activation=\"softmax\",\n",
    "# )\n",
    "\n",
    "model = tf.keras.applications.VGG16(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "\n",
    "\n",
    "# VGG16 pre-trained model without fully connected layers and with different input dimensions\n",
    "model = tf.keras.applications.VGG16(\n",
    "    weights = \"imagenet\", \n",
    "    include_top=False, \n",
    "    input_shape = (image_w, image_h, 3)\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b98e13b0-2942-4a9f-9559-789b05d83341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv2 False\n",
      "3 block1_pool False\n",
      "4 block2_conv1 False\n",
      "5 block2_conv2 False\n",
      "6 block2_pool False\n",
      "7 block3_conv1 False\n",
      "8 block3_conv2 False\n",
      "9 block3_conv3 False\n",
      "10 block3_pool False\n",
      "11 block4_conv1 False\n",
      "12 block4_conv2 False\n",
      "13 block4_conv3 False\n",
      "14 block4_pool False\n",
      "15 block5_conv1 False\n",
      "16 block5_conv2 False\n",
      "17 block5_conv3 False\n",
      "18 block5_pool False\n"
     ]
    }
   ],
   "source": [
    "# Freezing the layers we don't want to train (here I freeze  until the end of block 2 = 7 layers)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name, layer.trainable)\n",
    "    \n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c62080b1-6c89-4077-a6af-ad1e501c146a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "new_fc1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "new_predictions (Dense)      (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 16,813,381\n",
      "Trainable params: 2,098,693\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Adding custom layers to create a new model \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "\n",
    "new_model = Sequential([\n",
    "    model,\n",
    "    Flatten(name='flatten'),\n",
    "    Dense(256, activation='relu', name='new_fc1', kernel_initializer=\"HeNormal\"),\n",
    "    Dense(5, activation='softmax', name='new_predictions')\n",
    "])\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e54941b2-8ee5-4fd2-a6ec-d545245a111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001,)\n",
    "\n",
    "new_model.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "    optimizer = optimizer, \n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c55ee-26d5-4b9c-bf9d-6c7851c4c3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-19 22:13:31.663496: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/87 [================>.............] - ETA: 13:35 - loss: 5.1678 - accuracy: 0.6513"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_model.fit(train_ds, validation_data=val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b28183-212a-4563-8a65-5ab7e1dd81a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
